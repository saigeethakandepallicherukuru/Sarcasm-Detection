{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.linear_model as lm\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import pipeline,metrics, grid_search \n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "with open('sarcasm_dataset.txt','r') as fname:\n",
    "    file_content = fname.readlines()\n",
    "random.shuffle(file_content)\n",
    "output = 'tweets' + \"\\t\" + 'label' + \"\\n\"\n",
    "for tweet_content in file_content:    \n",
    "    tweet, label = tweet_content[:-3], tweet_content[-3]\n",
    "    output += tweet + \"\\t\" + label + \"\\n\"\n",
    "    \n",
    "outputfile = open('dataset_csv.csv',\"w\")\n",
    "outputfile.write(output)\n",
    "outputfile.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>Blob Polarity</th>\n",
       "      <th>Blob Subjectivity</th>\n",
       "      <th>Capitalization</th>\n",
       "      <th>Negative Sentiment</th>\n",
       "      <th>POS_1</th>\n",
       "      <th>POS_2</th>\n",
       "      <th>POS_3</th>\n",
       "      <th>POS_4</th>\n",
       "      <th>...</th>\n",
       "      <th>first half Blob Subjectivity</th>\n",
       "      <th>first half sentiment</th>\n",
       "      <th>negative Sentiment first half</th>\n",
       "      <th>negative Sentiment second half</th>\n",
       "      <th>positive Sentiment first half</th>\n",
       "      <th>positive Sentiment second half</th>\n",
       "      <th>second half Blob Polarity</th>\n",
       "      <th>second half Blob Subjectivity</th>\n",
       "      <th>second half sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.80000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.80000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.541667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.153409</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.632576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label  Blob Polarity  Blob Subjectivity  Capitalization  \\\n",
       "0           0      1        0.50000                0.6               0   \n",
       "1           1      1       -0.80000                0.9               0   \n",
       "2           2      0       -0.50000                1.0               0   \n",
       "3           3      0       -0.80000                0.9               1   \n",
       "4           4      1        0.78125                0.6               1   \n",
       "\n",
       "   Negative Sentiment  POS_1  POS_2  POS_3  POS_4    ...      \\\n",
       "0            0.031250    2.0    0.0    2.0    0.0    ...       \n",
       "1            1.444444    3.0    0.0    3.0    1.0    ...       \n",
       "2            0.725000    3.0    1.0    2.0    2.0    ...       \n",
       "3            0.778409    1.0    0.0    7.0    3.0    ...       \n",
       "4            0.039062    4.0    0.0    2.0    1.0    ...       \n",
       "\n",
       "   first half Blob Subjectivity  first half sentiment  \\\n",
       "0                           0.6              0.593750   \n",
       "1                           0.9             -0.638889   \n",
       "2                           1.0             -0.600000   \n",
       "3                           0.9             -0.541667   \n",
       "4                           0.6              0.601562   \n",
       "\n",
       "   negative Sentiment first half  negative Sentiment second half  \\\n",
       "0                       0.031250                        0.000000   \n",
       "1                       0.819444                        0.625000   \n",
       "2                       0.725000                        0.000000   \n",
       "3                       0.625000                        0.153409   \n",
       "4                       0.039062                        0.000000   \n",
       "\n",
       "   positive Sentiment first half  positive Sentiment second half  \\\n",
       "0                       0.625000                          0.0000   \n",
       "1                       0.180556                          0.1250   \n",
       "2                       0.125000                          0.0000   \n",
       "3                       0.083333                          0.0625   \n",
       "4                       0.640625                          0.0000   \n",
       "\n",
       "   second half Blob Polarity  second half Blob Subjectivity  \\\n",
       "0                        0.0                            0.0   \n",
       "1                        0.0                            0.0   \n",
       "2                        0.0                            0.0   \n",
       "3                        0.0                            0.0   \n",
       "4                        0.0                            0.0   \n",
       "\n",
       "   second half sentiment  sentiment  \n",
       "0               0.000000   0.593750  \n",
       "1              -0.500000  -1.138889  \n",
       "2               0.000000  -0.600000  \n",
       "3              -0.090909  -0.632576  \n",
       "4               0.000000   0.601562  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame()\n",
    "df = pandas.read_csv(\"dataset_csv.csv\", header=0, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pandas.DataFrame()\n",
    "test = pandas.DataFrame()\n",
    "\n",
    "train = df[0:1500]\n",
    "test = df[1501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vec=TfidfVectorizer(analyzer=\"word\",max_features=None,strip_accents='unicode',token_pattern=r'\\w{1,}',lowercase=True,ngram_range=(1,3),min_df=2,use_idf=True,smooth_idf=True,norm=\"l2\",sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(train['tweets'],train['label'],test_size=0.4,random_state=2,stratify=train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train=tfidf_vec.fit_transform(x_train)\n",
    "x_test=tfidf_vec.transform(x_test)\n",
    "x_train=x_train.toarray()\n",
    "x_test=x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputfile = open('dataset_train1.txt',\"w\")\n",
    "outputfile.write(x_train)\n",
    "outputfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_mod = lm.LogisticRegression(C=0.30,penalty=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = list(linear_mod.predict(x_test))\n",
    "target = list(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924428822496\n",
      "0.924428822496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score\n",
    "\n",
    "print f1_score(y_test,linear_mod.predict(x_test))   \n",
    "print f1_score(pred, target)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=18,n_iter=9,algorithm='randomized', random_state=None, tol=0.0)\n",
    "svd.fit(x_train)\n",
    "x_train=svd.transform(x_train)\n",
    "x_test=svd.transform(x_test)\n",
    "scl = StandardScaler()\n",
    "x_train=scl.fit_transform(x_train)\n",
    "x_test=scl.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(\n",
    "            analyzer=\"word\",max_features=None,\n",
    "            token_pattern=r'\\w{1,}',strip_accents='unicode',\n",
    "            lowercase=True,ngram_range=(1,3),\n",
    "            min_df=2,use_idf=True,\n",
    "            smooth_idf=True,norm=\"l2\",\n",
    "            sublinear_tf=True)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(train['tweets'],train['label'],test_size=0.4,random_state=2,stratify=train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tfidf_matrix=tfidf_vec.fit_transform(x_train)\n",
    "test_tfidf_matrix=tfidf_vec.fit_transform(x_test)\n",
    "\n",
    "train = pandas.DataFrame(train_tfidf_matrix.toarray())\n",
    "test = pandas.DataFrame(test_tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(algorithm=\"randomized\", random_state=None, tol=0.0)\n",
    "scl = StandardScaler()\n",
    "lr = lm.LogisticRegression(class_weight=\"balanced\", tol = 0.0001)\n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "    \t\t\t\t\t\t ('scl', scl),\n",
    "                    \t     ('lr', lr)])\n",
    "\n",
    "param_grid = {'svd__n_components' : [200,250,300,350,400],\n",
    "                 'svd__n_iter':[3,4,5],\n",
    "                 'lr__C': [10,11,12,13,14,15,16,17],\n",
    "                  'lr__penalty':[\"l1\",\"l2\"]}\n",
    "\n",
    "f_scorer = metrics.make_scorer(f1_score, greater_is_better = True)\n",
    "\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring=f_scorer,\n",
    "                                     verbose=10, n_jobs=-1, iid=True, refit=True, cv=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.867384 -   5.8s\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.896057 -   5.9s\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.922034 -   6.0s\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.867384 -   6.1s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.864469 -   6.0s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200 ..\n",
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.905797 -   6.1s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   13.7s\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.920962 -   6.5s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n",
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.910959 -   7.0s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=200, score=0.903226 -   5.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.923636 -   4.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   19.9s\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.876812 -   6.6s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.924658 -   6.4s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.871795 -   5.4s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.917563 -   4.8s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250 ..\n",
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.917808 -   5.8s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.875445 -   4.9s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.907850 -   5.4s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.9s\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=250, score=0.917563 -   5.5s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n",
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.888889 -   5.6s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.917808 -   6.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.908425 -   6.0s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.920415 -   6.1s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.880866 -   7.1s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.915751 -   5.8s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   39.1s\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.886525 -   5.7s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.910394 -   6.0s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.870504 -   6.2s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=300, score=0.914676 -   7.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.904762 -   6.2s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.920290 -   6.3s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.914089 -   6.5s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.872340 -   8.9s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.898551 -   8.8s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   58.4s\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.873646 -   8.6s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.920415 -   8.8s\n",
      "[CV] svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=350, score=0.901818 -   7.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.868327 -  10.1s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.910959 -   8.9s\n",
      "[CV] svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=3, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.891304 -   8.9s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n",
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.872727 -   8.0s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.910345 -   7.0s\n",
      "[CV] svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=4, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.903226 -   9.4s\n",
      "[CV] svd__n_iter=3, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.871429 -   9.7s\n",
      "[CV] svd__n_iter=3, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.917241 -  10.6s\n",
      "[CV] svd__n_iter=3, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svd__n_iter=4, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n",
      "[CV] svd__n_iter=4, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svd__n_iter=4, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n",
      "[CV]  svd__n_iter=5, lr__penalty=l1, lr__C=10, svd__n_components=400, score=0.909747 -  11.4s\n",
      "[CV] svd__n_iter=5, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svd__n_iter=5, lr__penalty=l2, lr__C=10, svd__n_components=200 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-12:\n",
      "Process PoolWorker-11:\n",
      "Process PoolWorker-10:\n",
      "Process PoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    self.run()\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 359, in get\n",
      "    task = get()\n",
      "    return recv()\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    racquire()\n",
      "  File \"/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, y_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"FFC\").setLevel(logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.linear_model as lm\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import pipeline,metrics, grid_search \n",
    "from sklearn.metrics import f1_score,precision_score\n",
    "from numpy import genfromtxt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "with open('sarcasm_dataset.txt','r') as fname:\n",
    "    file_content = fname.readlines()\n",
    "random.shuffle(file_content)\n",
    "\n",
    "output = 'tweets' + \"\\t\" + 'label' + \"\\n\"\n",
    "\n",
    "for tweet_content in file_content:    \n",
    "    tweet, label = tweet_content[:-3], tweet_content[-3]\n",
    "    output += tweet + \"\\t\" + label + \"\\n\"\n",
    "    \n",
    "outputfile = open('dataset_csv.csv',\"w\")\n",
    "outputfile.write(output)\n",
    "outputfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "train = pandas.DataFrame()\n",
    "test = pandas.DataFrame()\n",
    "\n",
    "df = pandas.read_csv(\"dataset_csv.csv\", header=0, sep='\\t')\n",
    "\n",
    "train = df[0:1500]\n",
    "test = df[1501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(\n",
    "            analyzer=\"word\",max_features=None,\n",
    "            token_pattern=r'\\w{1,}',strip_accents='unicode',\n",
    "            lowercase=True,ngram_range=(1,3),\n",
    "            min_df=2,use_idf=True,\n",
    "            smooth_idf=True,norm=\"l2\",\n",
    "            sublinear_tf=True)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(train['tweets'],train['label'],test_size=0.4,random_state=2,stratify=train['label'])\n",
    "\n",
    "train_tfidf_matrix=tfidf_vec.fit_transform(x_train)\n",
    "test_tfidf_matrix=tfidf_vec.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pandas.DataFrame(train_tfidf_matrix.toarray())\n",
    "test = pandas.DataFrame(test_tfidf_matrix.toarray())\n",
    "\n",
    "svd = TruncatedSVD(algorithm=\"randomized\", random_state=None, tol=0.0)\n",
    "scl = StandardScaler()\n",
    "lr = lm.LogisticRegression(class_weight=\"balanced\", tol = 0.0001)\n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "    \t\t\t\t\t\t ('scl', scl),\n",
    "                    \t     ('lr', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components' : [250],\n",
    "                 'svd__n_iter':[1],\n",
    "                 'lr__C': [11],\n",
    "                  'lr__penalty':[\"l1\"]}\n",
    "\n",
    "f_scorer = metrics.make_scorer(f1_score, greater_is_better = True)\n",
    "\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring=f_scorer,\n",
    "                                     verbose=10, n_jobs=-1, iid=True, refit=True, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train, y_train)\n",
    "print(\"Best score: %0.3f\" % model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "\tlr__C: 11\n",
      "\tlr__penalty: 'l1'\n",
      "\tsvd__n_components: 250\n",
      "\tsvd__n_iter: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "\tprint(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svd', TruncatedSVD(algorithm='randomized', n_components=250, n_iter=1,\n",
       "       random_state=None, tol=0.0)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=11, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model.best_estimator_\n",
    "best_model.fit(train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (600,2216) and (3108,250) not aligned: 2216 (dim 1) != 3108 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-36178f7137f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/truncated_svd.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m    200\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/surajr/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (600,2216) and (3108,250) not aligned: 2216 (dim 1) != 3108 (dim 0)"
     ]
    }
   ],
   "source": [
    "preds = best_model.predict(test)\n",
    "preds=list(preds)\n",
    "target_labels=list(y_test)\n",
    "print f1_score(target_labels,preds,average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
